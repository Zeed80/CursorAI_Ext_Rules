# ü§ñ CursorAI Autonomous Extension

<div align="right">

[English](#-cursorai-autonomous-extension-english) | [–†—É—Å—Å–∫–∏–π](README_RU.md)

</div>

> ## üéâ **FREE & AUTONOMOUS AI DEVELOPMENT** üéâ
> 
> ### **Work Completely Free with Local Models!**
> 
> The extension provides **fully autonomous development system** that works:
> 
> - ‚úÖ **100% FREE** - use local models (Ollama, LLM Studio) - **$0 cost forever**
> - ‚úÖ **Your own API keys** - use your OpenAI, Anthropic, Google accounts - pay only for usage
> - ‚úÖ **No CursorAI requirements** - works independently, no Background Agents API needed
> - ‚úÖ **Full autonomy** - agents work continuously in the background
> - ‚úÖ **Optional CursorAI integration** - if you have Pro plan and want to use it
> 
> ### **üöÄ Quick Start (Free)**
> 
> ```bash
> # 1. Install Ollama (takes 2 minutes)
> # Download from https://ollama.ai/
> 
> # 2. Download free models
> ollama pull codellama
> ollama pull mistral
> 
> # 3. Install extension and enable autonomous mode
> # Done! Your free AI development team is ready!
> ```
> 
> **You pay NOTHING** - all processing happens on your computer!

> ## ‚ö†Ô∏è **OPTIONAL: CursorAI Background Agents** ‚ö†Ô∏è
> 
> ### **Only if you want to use CursorAI's official Background Agents**
> 
> If you decide to use CursorAI's **Background Agents API** (optional feature), be aware:
> 
> - ‚ö†Ô∏è Requires **Usage-based pricing** enabled in Cursor
> - ‚ö†Ô∏è Requires **Spend Limit** (minimum $2)
> - ‚ö†Ô∏è **Additional costs** beyond your subscription
> - ‚ö†Ô∏è Can accumulate expenses with intensive use
> 
> **Recommendation:** Start with **free local models** (Ollama). Enable CursorAI integration only if you need it for specific tasks like:
> - Solution consolidation from multiple agents
> - File editing with Composer preview
> 
> **The extension works perfectly without CursorAI Background Agents!**

> ## üåü **NEW IN VERSION 0.3.0** üåü
> 
> ### **True Autonomous Operation with Local Models**
> 
> - ‚úÖ **$0 cost operation** - use only local models (Ollama, LLM Studio)
> - ‚úÖ **Hybrid mode** - combine local models with cloud APIs (OpenAI, Google, Anthropic)
> - ‚úÖ **Optional CursorAI integration** - use CursorAI only for specific tasks
> - ‚úÖ **Swarm orchestration** - autonomous agents work continuously in the background
> - ‚úÖ **Prioritized task queue** - immediate, high, medium, low priorities
> - ‚úÖ **Real-time monitoring** - file watcher triggers tasks automatically
> - ‚úÖ **Health monitoring** - auto-restart agents on failures
> - ‚úÖ **Cost optimization** - prompt caching, request batching, cost monitoring
> - ‚úÖ **UI improvements** - context menu for task creation, dashboard panel
> - ‚úÖ **Detailed logging** - Output Channel with detailed task progress, agent actions, and results

---

<div align="center">

[![Version](https://img.shields.io/badge/version-0.3.0-blue.svg)](https://github.com/Zeed80/CursorAI_Ext_Rules)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/Zeed80/CursorAI_Ext_Rules/blob/main/LICENSE)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue)](https://www.typescriptlang.org/)
[![VS Code](https://img.shields.io/badge/VS%20Code-1.80+-blue)](https://code.visualstudio.com/)
[![GitHub](https://img.shields.io/badge/GitHub-Zeed80/CursorAI__Ext_Rules-blue)](https://github.com/Zeed80/CursorAI_Ext_Rules)
[![GitHub stars](https://img.shields.io/github/stars/Zeed80/CursorAI_Ext_Rules?style=social)](https://github.com/Zeed80/CursorAI_Ext_Rules/stargazers)

**Autonomous extension for CursorAI with virtual user and self-improvement system**

[Installation](#-installation) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Contributing](#-contributing)

</div>

---

<a id="cursorai-autonomous-extension-english"></a>

## üìã Description

**CursorAI Autonomous Extension** ‚Äî an extension that transforms your IDE into a fully autonomous development system. The extension works **without requiring CursorAI's Background Agents API**, using local models (Ollama, LLM Studio) or cloud APIs (OpenAI, Google, Anthropic).

### üéØ Core Idea

Even weak coding models can write better code than top models if they:
- ‚úÖ Use deep code analysis before writing
- ‚úÖ Check syntax via MCP Context7
- ‚úÖ Verify facts via web search
- ‚úÖ Follow adaptive project rules
- ‚úÖ Coordinate specialized agents
- ‚úÖ **Work autonomously in the background**

## ‚ú® Features

### ü§ñ Autonomous Mode (NEW!)

**True autonomous operation:**

- **SwarmOrchestrator** ‚Äî coordinates multiple agent workers
- **AgentWorker** ‚Äî autonomous agents running in infinite loops
- **TaskQueue** ‚Äî prioritized task queue (immediate, high, medium, low)
- **MessageBus** ‚Äî peer-to-peer communication between agents
- **FileWatcher** ‚Äî real-time file monitoring triggers automatic tasks
- **HealthMonitor** ‚Äî auto-restart agents on failures
- **No supervision required** ‚Äî agents work continuously when IDE is open

### üé≠ Agent Orchestrator

Automatically coordinates specialized AI agents:

- **Backend Developer** ‚Äî backend development (PHP, PostgreSQL, API)
- **Frontend Developer** ‚Äî frontend development (HTML, CSS, JavaScript)
- **Software Architect** ‚Äî architecture and planning
- **Data Analyst** ‚Äî performance analysis and optimization
- **DevOps Engineer** ‚Äî infrastructure and deployment (Docker, CI/CD)
- **QA Engineer** ‚Äî testing (unit, integration, e2e)

**Orchestrator:**
- Automatically selects suitable agents for tasks
- Coordinates work between agents
- Checks quality via MCP Context7 and web search
- Manages tasks and their priorities
- **Brainstorming with task variations** ‚Äî creates different formulations
- **Deviation control** ‚Äî checks solution alignment
- **Ensemble refinement** ‚Äî multiple models propose improvements

### üí∞ Cost Optimization (NEW!)

**Intelligent model selection:**

- **HybridModelProvider** ‚Äî automatically chooses the best model:
  - Local models (Ollama, LLM Studio) for simple tasks - $0
  - Cheap cloud APIs (OpenAI GPT-3.5) for medium tasks - ~$0.01/task
  - Expensive models (GPT-4, Claude) for complex tasks only
- **SmartModelSelector** ‚Äî assesses task complexity
- **PromptCache** ‚Äî caches prompts to reduce API calls (LRU, configurable TTL)
- **RequestBatcher** ‚Äî batches multiple small requests
- **CostMonitor** ‚Äî tracks expenses per model and agent
- **Monthly budget control** ‚Äî stops when budget is reached

**Cost scenarios:**
- **$0/month** ‚Äî use only local models (Ollama)
- **$5-30/month** ‚Äî hybrid (local + cheap cloud APIs)
- **Optional CursorAI** ‚Äî use only for specific tasks (consolidation, file editing)

### üîß Model Providers (NEW!)

**Support for multiple LLM providers:**

- **Ollama** ‚Äî local models (codellama, mistral, etc.)
- **LLM Studio** ‚Äî local models via API
- **OpenAI** ‚Äî GPT-3.5, GPT-4
- **Anthropic** ‚Äî Claude (all versions)
- **Google** ‚Äî Gemini Pro
- **CursorAI** ‚Äî optional, only for specific tasks

**Configuration per agent:**
- Each agent can use a different provider
- Automatic fallback if primary provider fails
- Provider priorities in hybrid mode

### üé® CursorAI Integration (Optional, NEW!)

**Strategic use of CursorAI:**

- **Chat API** ‚Äî solution consolidation from multiple agents
- **Composer API** ‚Äî safe file editing with preview
- **Configurable usage** ‚Äî choose when to use CursorAI:
  - `consolidation` ‚Äî for merging agent solutions
  - `file-editing` ‚Äî for applying file changes
  - `never` ‚Äî don't use CursorAI at all

### üë§ Virtual User

Autonomous agent that:

- Understands project goals
- Monitors task execution
- Automatically makes decisions about approving proposals
- Initiates new tasks to improve the project
- Consults with other agents

### üîÑ Self-Improvement System

Continuously improves work quality:

- **Performance Monitor** ‚Äî tracks agent performance metrics
- **Knowledge Searcher** ‚Äî searches for best practices information
- **Rule Updater** ‚Äî automatically updates rules
- **Agent Optimizer** ‚Äî optimizes agent work

### üìê Adaptive Rules

Automatically adapts rules to the project:

- Analyzes project structure
- Determines technology stack
- Generates rules based on analysis
- Updates rules when the project changes
- Versions rules for rollback

### üîç Integration with MCP Context7 and Web Search

**Critically important:** Always checks syntax and facts before writing code:

- ‚úÖ Syntax checking via MCP Context7
- ‚úÖ Library currency checking via web search
- ‚úÖ Best practices search
- ‚úÖ Security checking

### üß† Advanced MCP Client (NEW!)

**Expanded capabilities:**

- **File operations** ‚Äî read, write, move, delete, search
- **Git operations** ‚Äî status, commit, diff, branch, merge, stash, rebase
- **Code search** ‚Äî semantic search, grep, find references
- **Context management** ‚Äî analyze dependencies, get file summaries
- **Test runner integration** ‚Äî auto-detect framework, run tests
- **Linter integration** ‚Äî read diagnostics, suggest fixes

### üé® Modern UI (Improved!)

- **Agent status panel** ‚Äî TreeView with real-time updates
- **Settings panel** ‚Äî WebView with tabbed interface (NEW: Autonomous Mode tab)
- **Dashboard panel** (NEW!) ‚Äî cost statistics, agent activity, system health
- **Quick menu** ‚Äî quick access to all tools
- **Status bar** ‚Äî system state indicators (shows autonomous mode status)
- **Context menu** (NEW!) ‚Äî create tasks directly from Explorer
- **Analytics** ‚Äî task execution statistics

## üöÄ Installation

### Method 1: Drag and drop .vsix file ‚≠ê (Simplest)

1. Build the extension:
   ```bash
   npm run package
   ```

2. Open CursorAI

3. Press `Ctrl+Shift+X` (or `Cmd+Shift+X` on macOS)

4. **Drag the `.vsix` file into the CursorAI window**

5. Done! Extension is installed

üìñ More details: [QUICK_INSTALL.md](QUICK_INSTALL.md)

### Method 2: Automatic installation (Recommended)

**Windows:**
```bash
install.bat
```

**Linux/macOS:**
```bash
chmod +x install.sh
./install.sh
```

**Universal method (Node.js):**
```bash
npm run install
```

The autonomous installer automatically:
- ‚úì Checks for Node.js and npm
- ‚úì Installs all dependencies
- ‚úì Compiles the project
- ‚úì Builds the extension into .vsix
- ‚úì Installs the extension in CursorAI

üìñ More details: [INSTALL.md](INSTALL.md)

### Method 3: Manual installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Zeed80/CursorAI_Ext_Rules.git
   cd CursorAI_Ext_Rules
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Build the extension:
   ```bash
   npm run package
   ```

4. Install the built .vsix file in CursorAI:
   ```bash
   code --install-extension cursor-ai-autonomous-extension-0.3.0.vsix
   ```

üìñ More details: [BUILD.md](BUILD.md)

## ‚ö° Quick Start

### 0. Prerequisites

**Option A: Local Models Only ($0 cost)**

1. Install [Ollama](https://ollama.ai/)
2. Download models:
   ```bash
   ollama pull codellama
   ollama pull mistral
   ollama pull llama2
   ```
3. Configure extension settings (see below)

**Option B: Hybrid Mode ($5-30/month)**

1. Install Ollama (optional)
2. Get API keys:
   - OpenAI: https://platform.openai.com/api-keys
   - Anthropic: https://console.anthropic.com/
   - Google: https://makersuite.google.com/app/apikey
3. Configure extension settings (see below)

**Option C: With CursorAI Integration (Optional)**

1. Have a CursorAI Pro plan
2. Complete Option A or B
3. Enable CursorAI integration in settings

### 1. Extension Activation

After installation, the extension activates automatically when opening a project.

### 2. Configure Settings

**Method 1: Through Settings Panel (Recommended)**

1. Press `Ctrl+Shift+A` (Quick Menu)
2. Select "‚öô Settings"
3. Configure:
   - **Agents tab** ‚Äî select providers and models for each agent
   - **Autonomous Mode tab** (NEW!) ‚Äî configure autonomous operation:
     - Enable autonomous mode
     - Set up hybrid mode (preferLocal, monthlyBudget)
     - Choose when to use CursorAI (useCursorAIFor)
     - Configure CursorAI integration (useChat, useComposer)

**Method 2: Through settings.json**

```json
{
  // Autonomous Mode Settings (NEW!)
  "cursor-autonomous.autonomousMode": true,
  
  // Hybrid Model Provider (NEW!)
  "cursor-autonomous.hybridMode": {
    "enabled": true,
    "preferLocal": true,
    "monthlyBudget": 20
  },
  
  // CursorAI Integration (NEW!)
  "cursor-autonomous.useCursorAIFor": ["consolidation", "file-editing"],
  "cursor-autonomous.cursorIntegration": {
    "useChat": true,
    "useComposer": true,
    "autoApplyComposer": false
  },
  
  // Agent Configuration
  "cursor-autonomous.agents": {
    "backend": {
      "enabled": true,
      "provider": "ollama",
      "model": "codellama",
      "temperature": 0.7
    },
    "frontend": {
      "enabled": true,
      "provider": "ollama",
      "model": "mistral",
      "temperature": 0.7
    }
    // ... other agents
  },
  
  // General Settings
  "cursor-autonomous.enableVirtualUser": false,
  "cursor-autonomous.autoImprove": true,
  "cursor-autonomous.enableOrchestrator": true
}
```

### 3. Enable Autonomous Mode

**Method 1: Through Quick Menu**
1. Press `Ctrl+Shift+A`
2. Select "ü§ñ Enable Autonomous Mode"

**Method 2: Through Command Palette**
- `Ctrl+Shift+P` ‚Üí "CursorAI Autonomous: Enable Autonomous Mode"

**Method 3: Through Status Bar**
- Click on `ü§ñ CursorAI` button in status bar

**What happens:**
- SwarmOrchestrator starts
- Agent workers initialize
- FileWatcher starts monitoring
- HealthMonitor starts tracking
- Status bar shows "Autonomous Mode Active" with green background

### 4. Create Tasks

**Method 1: Context Menu (NEW!)**
1. Right-click on file/folder in Explorer
2. Select "CursorAI Autonomous" submenu:
   - Create Task
   - Refactor (Extract Function/Class/Method/Component/Module)
   - Check Quality
   - Add Tests
   - Optimize Code

**Method 2: Quick Menu**
1. Press `Ctrl+Shift+A`
2. Select "‚ûï Create Task" or "‚ûï Create Prioritized Task" (NEW!)
3. Enter description
4. Select priority (immediate, high, medium, low)

**Method 3: Command**
- `Ctrl+Shift+P` ‚Üí "CursorAI Autonomous: Create Task"

### 5. Monitor System

**Output Channel for Logging (NEW!):**
1. Press `Ctrl+Shift+U` (or `View > Output`)
2. Select "CursorAI Autonomous" from dropdown
3. View detailed orchestrator logs:
   - ‚úÖ Orchestrator start/stop
   - üöÄ Task start with description and priority
   - üìä Task execution progress
   - ü§ñ Agent actions
   - üìù List of changed files
   - ‚úÖ Quality check results
   - ‚ùå Errors with details
   - ‚è±Ô∏è Task execution time

**Status Bar:**
- `ü§ñ CursorAI ‚úì` (green) ‚Äî Autonomous mode active
- `üë§ Virtual User` ‚Äî Toggle virtual user
- `üìä Status` ‚Äî Open status panel

**Dashboard Panel (NEW!):**
1. Press `Ctrl+Shift+A` ‚Üí "üìä Autonomous Stats"
2. View:
   - Cost statistics per model/agent
   - Agent activity (tasks completed, time spent)
   - System health (worker status, queue size)
   - Budget usage (daily, monthly)

**Status Panel:**
1. Press `Ctrl+Shift+S`
2. View all agents and their tasks

## üìñ Usage

### Working with Agents

#### Viewing Agent Status

**Sidebar (TreeView):**
1. Open CursorAI sidebar (ü§ñ icon)
2. Select "Agents"
3. Expand agent to view tasks

**Status Panel (WebView):**
1. Press `Ctrl+Shift+S`
2. View agent cards with details

#### Selecting Model for Agent

**Through Settings Panel:**
1. Press `Ctrl+Shift+A` ‚Üí "‚öô Settings"
2. Go to "Agents" tab
3. For each agent:
   - Select provider (Ollama, OpenAI, Anthropic, Google, LLM Studio, CursorAI)
   - Select model
   - Set temperature

**Available providers:**
- `ollama` ‚Äî Ollama (local, free)
- `llmstudio` ‚Äî LLM Studio (local, free)
- `openai` ‚Äî OpenAI (GPT-3.5, GPT-4)
- `anthropic` ‚Äî Anthropic (Claude)
- `google` ‚Äî Google (Gemini)
- `cursorai` ‚Äî CursorAI (requires Pro plan)

### Working with Tasks

#### Task Priorities (NEW!)

- **immediate** ‚Äî Interrupts current work, executes immediately
- **high** ‚Äî Executes as soon as possible
- **medium** ‚Äî Normal queue
- **low** ‚Äî Executes when agents are idle

#### Creating Prioritized Task

1. Press `Ctrl+Shift+A`
2. Select "‚ûï Create Prioritized Task"
3. Enter description
4. Select priority
5. Task is added to queue with specified priority

#### Viewing Task Queue

**Dashboard Panel:**
- Shows tasks in queue grouped by priority
- Shows currently executing tasks
- Shows completed tasks

### Cost Management (NEW!)

#### Monitoring Costs

**Dashboard Panel:**
1. Press `Ctrl+Shift+A` ‚Üí "üìä Autonomous Stats"
2. "Cost Statistics" section shows:
   - Total spent today/this month
   - Cost per model
   - Cost per agent
   - Budget usage percentage

#### Setting Budget

**Settings Panel:**
1. Go to "Autonomous Mode" tab
2. Set "Monthly Budget" (in USD)
3. System will:
   - Prefer free local models
   - Use cheap cloud APIs sparingly
   - Stop when budget is reached

#### Optimizing Costs

**Best practices:**
- ‚úÖ Enable `preferLocal` in hybrid mode
- ‚úÖ Set reasonable monthly budget ($10-30)
- ‚úÖ Use CursorAI only for specific tasks
- ‚úÖ Enable prompt caching (enabled by default)
- ‚úÖ Monitor costs daily through dashboard

### Project Quality Check

**Launch check:**
- Command: `Cursor Autonomous: Run Quality Check`
- Context menu: Right-click on folder ‚Üí "Check Quality"

**Check areas:**
- `full` ‚Äî Full quality check
- `code` ‚Äî Code quality check
- `architecture` ‚Äî Architecture check
- `performance` ‚Äî Performance check
- `security` ‚Äî Security check

## üèóÔ∏è Architecture

### Project Structure

```
CursorAI_Ext_Rules/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ extension.ts                          # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/                         # Orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.ts                  # Main orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator-logger.ts           # Output Channel logging (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ self-learning-orchestrator.ts    # Self-learning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ swarm-orchestrator.ts           # Swarm coordination (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file-watcher.ts                  # Real-time monitoring (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autonomous-orchestrator-integration.ts  # Integration (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brainstorming-manager.ts         # Brainstorming
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ solution-evaluator.ts            # Solution evaluation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task-deviation-controller.ts     # Deviation control
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ensemble-refinement-manager.ts   # Ensemble refinement
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project-analyzer.ts              # Project analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ agents/                               # Agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local-agent.ts                   # Base agent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend-agent.ts                 # Backend Developer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frontend-agent.ts                # Frontend Developer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ architect-agent.ts               # Software Architect
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyst-agent.ts                 # Data Analyst
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devops-agent.ts                  # DevOps Engineer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qa-agent.ts                      # QA Engineer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ virtual-user.ts                  # Virtual user
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ self-improver.ts                 # Self-improvement
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker/                          # Autonomous workers (NEW!)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ agent-worker.ts              # Agent worker
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ task-queue.ts                # Task queue
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ message-bus.ts               # Message bus
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ mcp-client.ts                # MCP client
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ health-monitor.ts            # Health monitor
‚îÇ   ‚îú‚îÄ‚îÄ integration/                          # Integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cursor-api.ts                    # CursorAI API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cursor-chat-integration.ts       # Chat integration (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cursor-composer-integration.ts   # Composer integration (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-provider.ts                # Model provider
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-providers/                 # Model providers (NEW!)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider-manager.ts          # Provider manager
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid-provider.ts           # Hybrid provider
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollama-provider.ts           # Ollama
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai-provider.ts           # OpenAI
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anthropic-provider.ts        # Anthropic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google-provider.ts           # Google
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cursorai-provider.ts         # CursorAI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings-manager.ts              # Settings manager
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui-integration.ts                # UI integration
‚îÇ   ‚îú‚îÄ‚îÄ optimization/                         # Optimization (NEW!)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-selector.ts                # Smart model selector
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt-cache.ts                  # Prompt caching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ request-batcher.ts               # Request batching
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cost-monitor.ts                  # Cost monitoring
‚îÇ   ‚îú‚îÄ‚îÄ self-improvement/                     # Self-improvement
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ performance-monitor.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge-searcher.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rule-updater.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent-optimizer.ts
‚îÇ   ‚îú‚îÄ‚îÄ storage/                              # Storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rules-integration.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rules-versioning.ts
‚îÇ   ‚îî‚îÄ‚îÄ ui/                                   # UI
‚îÇ       ‚îú‚îÄ‚îÄ agents-status-tree.ts            # TreeView
‚îÇ       ‚îú‚îÄ‚îÄ status-panel.ts                  # Status panel
‚îÇ       ‚îú‚îÄ‚îÄ settings-panel.ts                # Settings panel (updated)
‚îÇ       ‚îú‚îÄ‚îÄ dashboard-panel.ts               # Dashboard (NEW!)
‚îÇ       ‚îú‚îÄ‚îÄ context-menu-provider.ts         # Context menu (NEW!)
‚îÇ       ‚îú‚îÄ‚îÄ analytics-panel.ts               # Analytics
‚îÇ       ‚îî‚îÄ‚îÄ quick-access-panel.ts            # Quick menu
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ README.md (English)
‚îî‚îÄ‚îÄ README_RU.md (Russian)
```

### System Components

#### SwarmOrchestrator (NEW!)

Coordinates autonomous agent workers:
- Creates and manages AgentWorker instances
- Distributes tasks from TaskQueue
- Monitors worker health
- Handles real-time file changes

#### AgentWorker (NEW!)

Autonomous agent running in infinite loop:
- Pulls tasks from TaskQueue
- Communicates via MessageBus
- Uses MCPClient for operations
- Reports health status
- Auto-restarts on failures

#### TaskQueue (NEW!)

Prioritized task queue:
- 4 priority levels (immediate, high, medium, low)
- Swarm coordination (agents negotiate task assignment)
- Thread-safe operations
- Task persistence

#### MessageBus (NEW!)

Peer-to-peer communication:
- Topic-based pub/sub
- Direct agent-to-agent messaging
- Event broadcasting
- Message history

#### HybridModelProvider (NEW!)

Intelligent model selection:
- Assesses task complexity
- Chooses optimal model (local, cheap cloud, expensive cloud)
- Respects monthly budget
- Automatic fallback
- Cost tracking

#### FileWatcher (NEW!)

Real-time project monitoring:
- Watches file changes
- Triggers automatic tasks
- Debouncing for efficiency
- Pattern filtering

#### HealthMonitor (NEW!)

Agent health tracking:
- Checks worker heartbeats
- Detects stuck agents
- Auto-restarts failed workers
- Reports system health

#### OrchestratorLogger (NEW!)

Centralized logging to Output Channel:
- Outputs detailed task execution progress
- Shows agent actions in real-time
- Displays list of changed files
- Logs quality check results
- Shows errors with details and stack traces
- Automatically opens Output panel when orchestrator starts
- Formatted messages with emojis for easy reading

#### MCPClient (NEW!)

Multi-Agent Communication Protocol:
- File operations (CRUD, search)
- Git operations (status, commit, branch, merge, stash, rebase)
- Code search (semantic, grep, references)
- Test runner integration
- Linter integration

## üõ†Ô∏è Development

### Requirements

- **Node.js** version 18 or higher
- **TypeScript** 5.0 or higher
- **VS Code** 1.80 or higher
- **CursorAI** (for testing)

### Installing Dependencies

```bash
npm install
```

### Compilation

```bash
npm run compile
```

Or for automatic recompilation:

```bash
npm run watch
```

### Build

```bash
npm run package
```

### Testing

```bash
npm test
```

### Running in Development Mode

1. Open the project in VS Code
2. Press `F5`
3. Extension Development Host window opens
4. Extension runs in debug mode

## üìö Documentation

- [README.md](README.md) ‚Äî Main documentation (English)
- [README_RU.md](README_RU.md) ‚Äî –û—Å–Ω–æ–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (Russian)
- [BUILD.md](BUILD.md) ‚Äî Build instructions
- [INSTALL.md](INSTALL.md) ‚Äî Installation instructions
- [QUICK_INSTALL.md](QUICK_INSTALL.md) ‚Äî Quick installation
- [QUICK_ACCESS.md](QUICK_ACCESS.md) ‚Äî Quick access guide
- [UI_FEATURES.md](UI_FEATURES.md) ‚Äî UI features
- [IMPROVEMENTS.md](IMPROVEMENTS.md) ‚Äî Integration improvements
- [CHANGELOG.md](CHANGELOG.md) ‚Äî Change history

## üí∞ Cost Comparison

### Scenario 1: Free ($0/month)
```json
{
  "hybridMode": {
    "enabled": true,
    "preferLocal": true,
    "monthlyBudget": 0
  },
  "useCursorAIFor": ["never"],
  "agents": {
    "backend": { "provider": "ollama", "model": "codellama" },
    "frontend": { "provider": "ollama", "model": "mistral" }
  }
}
```
**Result:** Fully functional with local models only

### Scenario 2: Budget ($5-10/month)
```json
{
  "hybridMode": {
    "enabled": true,
    "preferLocal": true,
    "monthlyBudget": 10
  },
  "useCursorAIFor": ["never"],
  "agents": {
    "backend": { "provider": "openai", "model": "gpt-3.5-turbo" },
    "frontend": { "provider": "ollama", "model": "mistral" }
  }
}
```
**Result:** Hybrid mode with cheap cloud APIs for complex tasks

### Scenario 3: Premium ($20-50/month)
```json
{
  "hybridMode": {
    "enabled": true,
    "preferLocal": false,
    "monthlyBudget": 50
  },
  "useCursorAIFor": ["consolidation", "file-editing"],
  "agents": {
    "backend": { "provider": "openai", "model": "gpt-4" },
    "frontend": { "provider": "anthropic", "model": "claude-3-opus" }
  }
}
```
**Result:** Best quality with top models + CursorAI integration

## ü§ù Contributing

We welcome contributions! Please follow these steps:

1. **Fork** the repository
2. Create a **feature branch** (`git checkout -b feature/AmazingFeature`)
3. **Commit** changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to branch (`git push origin feature/AmazingFeature`)
5. Open a **Pull Request**

### Development Rules

- Follow TypeScript/ESLint code style
- Add tests for new functionality
- Update documentation when changing API
- Write clear commit messages

## üìù License

This project is distributed under the **MIT License**.

Full license text: [LICENSE](LICENSE)

## üÜò Support

### Report an Issue

1. Check existing [Issues](https://github.com/Zeed80/CursorAI_Ext_Rules/issues)
2. Create a new Issue with detailed description

### Ask a Question

- Create a [Discussion](https://github.com/Zeed80/CursorAI_Ext_Rules/discussions)
- Or contact through Issues

### Troubleshooting

#### Viewing Orchestrator Logs

**Output Channel "CursorAI Autonomous":**
1. Press `Ctrl+Shift+U` (or `View > Output`)
2. Select "CursorAI Autonomous" from dropdown
3. Logs automatically open when orchestrator starts
4. View:
   - Task execution progress
   - Agent actions
   - Changed files
   - Errors with details

**Extension Host Logs (for debugging):**
1. View ‚Üí Output ‚Üí "Log (Extension Host)"
2. Shows technical details and errors

#### Extension Not Activating

1. Check logs: View ‚Üí Output ‚Üí "Log (Extension Host)"
2. Check Output Channel: View ‚Üí Output ‚Üí "CursorAI Autonomous"
3. Ensure dependencies are installed: `npm install`
4. Check compiled files in `out/` directory
5. Reload window: `Ctrl+Shift+P` ‚Üí "Developer: Reload Window"

#### Autonomous Mode Not Starting

1. Check settings: `cursor-autonomous.autonomousMode` should be `true`
2. Check if agents are configured in settings
3. For local models: ensure Ollama is running
4. Check logs for errors

#### "Local agent X not found"

1. Open Settings Panel: `Ctrl+Shift+A` ‚Üí "‚öô Settings"
2. Go to "Agents" tab
3. Enable and configure all required agents
4. Ensure providers are installed (Ollama, API keys)

#### Ollama Connection Failed

1. Check Ollama is running: `ollama list`
2. Check Ollama server: `curl http://localhost:11434/api/tags`
3. Install models: `ollama pull codellama`
4. Restart extension: `Ctrl+Shift+P` ‚Üí "Developer: Reload Window"

#### High API Costs

1. Enable `preferLocal` in hybrid mode
2. Lower `monthlyBudget`
3. Use cheaper models (gpt-3.5-turbo instead of gpt-4)
4. Disable CursorAI integration: `useCursorAIFor: ["never"]`
5. Monitor costs in Dashboard Panel

## üéØ Roadmap

### Planned Features

- [ ] More LLM providers (Cohere, Mistral AI, Llama API)
- [ ] Enhanced swarm intelligence (voting, consensus)
- [ ] Cloud synchronization for rules and settings
- [ ] Team collaboration features
- [ ] Advanced cost analytics and predictions
- [ ] Automatic model fine-tuning on project data

### Known Limitations

- Some features may use fallback methods
- Internet connection required for cloud APIs and web search
- Local models may be slower than cloud APIs
- Autonomous mode consumes system resources

## üôè Acknowledgments

- [CursorAI](https://cursor.sh/) ‚Äî excellent IDE
- [Ollama](https://ollama.ai/) ‚Äî local LLM runner
- [VS Code Extension API](https://code.visualstudio.com/api) ‚Äî powerful API
- All project contributors

## üìû Contacts

- **GitHub**: [@Zeed80](https://github.com/Zeed80)
- **Issues**: [GitHub Issues](https://github.com/Zeed80/CursorAI_Ext_Rules/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Zeed80/CursorAI_Ext_Rules/discussions)

---

<div align="center">

[English](#-cursorai-autonomous-extension-english) | [–†—É—Å—Å–∫–∏–π](README_RU.md)

**Made with ‚ù§Ô∏è by the power of AI**

</div>
