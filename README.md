# ğŸ¤– CursorAI Autonomous Extension

<div align="right">

[English](#-cursorai-autonomous-extension-english) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README_RU.md)

</div>

> ## ğŸŒŸ **NEW IN VERSION 0.2.0** ğŸŒŸ
> 
> ### **True Autonomous Operation with Local Models**
> 
> The extension now supports **fully autonomous operation** using local models (Ollama, LLM Studio) **without requiring CursorAI's Background Agents API**!
> 
> ### **Key Features:**
> 
> - âœ… **$0 cost operation** - use only local models (Ollama, LLM Studio)
> - âœ… **Hybrid mode** - combine local models with cloud APIs (OpenAI, Google, Anthropic)
> - âœ… **Optional CursorAI integration** - use CursorAI only for specific tasks (consolidation, file editing)
> - âœ… **Swarm orchestration** - autonomous agents work continuously in the background
> - âœ… **Prioritized task queue** - immediate, high, medium, low priorities
> - âœ… **Real-time monitoring** - file watcher triggers tasks automatically
> - âœ… **Health monitoring** - auto-restart agents on failures
> - âœ… **Cost optimization** - prompt caching, request batching, cost monitoring
> - âœ… **UI improvements** - context menu for task creation, dashboard panel

> ## âš ï¸ **IMPORTANT INFORMATION** âš ï¸
> 
> ### **Research Project**
> 
> This project was created for **research purposes** to explore autonomous AI development capabilities. The project was created **100% automatically** in CursorAI.
> 
> ### **No CursorAI Background Agents Required**
> 
> Unlike version 0.1.0, the extension **no longer requires** CursorAI's Background Agents API or Usage-based pricing! You can:
> 
> - âœ… **Use only local models** (Ollama, LLM Studio) - $0 cost
> - âœ… **Use cloud APIs** (OpenAI, Google, Anthropic) - pay only for what you use
> - âœ… **Optional CursorAI integration** - if you have a Pro plan
> 
> **Minimal Configuration:**
> - Install Ollama (free)
> - Download models (codellama, mistral, etc.)
> - Enable autonomous mode
> - Done! System works continuously

---

<div align="center">

[![Version](https://img.shields.io/badge/version-0.2.0-blue.svg)](https://github.com/Zeed80/CursorAI_Ext_Rules)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/Zeed80/CursorAI_Ext_Rules/blob/main/LICENSE)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue)](https://www.typescriptlang.org/)
[![VS Code](https://img.shields.io/badge/VS%20Code-1.80+-blue)](https://code.visualstudio.com/)
[![GitHub](https://img.shields.io/badge/GitHub-Zeed80/CursorAI__Ext_Rules-blue)](https://github.com/Zeed80/CursorAI_Ext_Rules)
[![GitHub stars](https://img.shields.io/github/stars/Zeed80/CursorAI_Ext_Rules?style=social)](https://github.com/Zeed80/CursorAI_Ext_Rules/stargazers)

**Autonomous extension for CursorAI with virtual user and self-improvement system**

[Installation](#-installation) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Contributing](#-contributing)

</div>

---

<a id="cursorai-autonomous-extension-english"></a>

## ğŸ“‹ Description

**CursorAI Autonomous Extension** â€” an extension that transforms your IDE into a fully autonomous development system. The extension works **without requiring CursorAI's Background Agents API**, using local models (Ollama, LLM Studio) or cloud APIs (OpenAI, Google, Anthropic).

### ğŸ¯ Core Idea

Even weak coding models can write better code than top models if they:
- âœ… Use deep code analysis before writing
- âœ… Check syntax via MCP Context7
- âœ… Verify facts via web search
- âœ… Follow adaptive project rules
- âœ… Coordinate specialized agents
- âœ… **Work autonomously in the background**

## âœ¨ Features

### ğŸ¤– Autonomous Mode (NEW!)

**True autonomous operation:**

- **SwarmOrchestrator** â€” coordinates multiple agent workers
- **AgentWorker** â€” autonomous agents running in infinite loops
- **TaskQueue** â€” prioritized task queue (immediate, high, medium, low)
- **MessageBus** â€” peer-to-peer communication between agents
- **FileWatcher** â€” real-time file monitoring triggers automatic tasks
- **HealthMonitor** â€” auto-restart agents on failures
- **No supervision required** â€” agents work continuously when IDE is open

### ğŸ­ Agent Orchestrator

Automatically coordinates specialized AI agents:

- **Backend Developer** â€” backend development (PHP, PostgreSQL, API)
- **Frontend Developer** â€” frontend development (HTML, CSS, JavaScript)
- **Software Architect** â€” architecture and planning
- **Data Analyst** â€” performance analysis and optimization
- **DevOps Engineer** â€” infrastructure and deployment (Docker, CI/CD)
- **QA Engineer** â€” testing (unit, integration, e2e)

**Orchestrator:**
- Automatically selects suitable agents for tasks
- Coordinates work between agents
- Checks quality via MCP Context7 and web search
- Manages tasks and their priorities
- **Brainstorming with task variations** â€” creates different formulations
- **Deviation control** â€” checks solution alignment
- **Ensemble refinement** â€” multiple models propose improvements

### ğŸ’° Cost Optimization (NEW!)

**Intelligent model selection:**

- **HybridModelProvider** â€” automatically chooses the best model:
  - Local models (Ollama, LLM Studio) for simple tasks - $0
  - Cheap cloud APIs (OpenAI GPT-3.5) for medium tasks - ~$0.01/task
  - Expensive models (GPT-4, Claude) for complex tasks only
- **SmartModelSelector** â€” assesses task complexity
- **PromptCache** â€” caches prompts to reduce API calls (LRU, configurable TTL)
- **RequestBatcher** â€” batches multiple small requests
- **CostMonitor** â€” tracks expenses per model and agent
- **Monthly budget control** â€” stops when budget is reached

**Cost scenarios:**
- **$0/month** â€” use only local models (Ollama)
- **$5-30/month** â€” hybrid (local + cheap cloud APIs)
- **Optional CursorAI** â€” use only for specific tasks (consolidation, file editing)

### ğŸ”§ Model Providers (NEW!)

**Support for multiple LLM providers:**

- **Ollama** â€” local models (codellama, mistral, etc.)
- **LLM Studio** â€” local models via API
- **OpenAI** â€” GPT-3.5, GPT-4
- **Anthropic** â€” Claude (all versions)
- **Google** â€” Gemini Pro
- **CursorAI** â€” optional, only for specific tasks

**Configuration per agent:**
- Each agent can use a different provider
- Automatic fallback if primary provider fails
- Provider priorities in hybrid mode

### ğŸ¨ CursorAI Integration (Optional, NEW!)

**Strategic use of CursorAI:**

- **Chat API** â€” solution consolidation from multiple agents
- **Composer API** â€” safe file editing with preview
- **Configurable usage** â€” choose when to use CursorAI:
  - `consolidation` â€” for merging agent solutions
  - `file-editing` â€” for applying file changes
  - `never` â€” don't use CursorAI at all

### ğŸ‘¤ Virtual User

Autonomous agent that:

- Understands project goals
- Monitors task execution
- Automatically makes decisions about approving proposals
- Initiates new tasks to improve the project
- Consults with other agents

### ğŸ”„ Self-Improvement System

Continuously improves work quality:

- **Performance Monitor** â€” tracks agent performance metrics
- **Knowledge Searcher** â€” searches for best practices information
- **Rule Updater** â€” automatically updates rules
- **Agent Optimizer** â€” optimizes agent work

### ğŸ“ Adaptive Rules

Automatically adapts rules to the project:

- Analyzes project structure
- Determines technology stack
- Generates rules based on analysis
- Updates rules when the project changes
- Versions rules for rollback

### ğŸ” Integration with MCP Context7 and Web Search

**Critically important:** Always checks syntax and facts before writing code:

- âœ… Syntax checking via MCP Context7
- âœ… Library currency checking via web search
- âœ… Best practices search
- âœ… Security checking

### ğŸ§  Advanced MCP Client (NEW!)

**Expanded capabilities:**

- **File operations** â€” read, write, move, delete, search
- **Git operations** â€” status, commit, diff, branch, merge, stash, rebase
- **Code search** â€” semantic search, grep, find references
- **Context management** â€” analyze dependencies, get file summaries
- **Test runner integration** â€” auto-detect framework, run tests
- **Linter integration** â€” read diagnostics, suggest fixes

### ğŸ¨ Modern UI (Improved!)

- **Agent status panel** â€” TreeView with real-time updates
- **Settings panel** â€” WebView with tabbed interface (NEW: Autonomous Mode tab)
- **Dashboard panel** (NEW!) â€” cost statistics, agent activity, system health
- **Quick menu** â€” quick access to all tools
- **Status bar** â€” system state indicators (shows autonomous mode status)
- **Context menu** (NEW!) â€” create tasks directly from Explorer
- **Analytics** â€” task execution statistics

## ğŸš€ Installation

### Method 1: Drag and drop .vsix file â­ (Simplest)

1. Build the extension:
   ```bash
   npm run package
   ```

2. Open CursorAI

3. Press `Ctrl+Shift+X` (or `Cmd+Shift+X` on macOS)

4. **Drag the `.vsix` file into the CursorAI window**

5. Done! Extension is installed

ğŸ“– More details: [QUICK_INSTALL.md](QUICK_INSTALL.md)

### Method 2: Automatic installation (Recommended)

**Windows:**
```bash
install.bat
```

**Linux/macOS:**
```bash
chmod +x install.sh
./install.sh
```

**Universal method (Node.js):**
```bash
npm run install
```

The autonomous installer automatically:
- âœ“ Checks for Node.js and npm
- âœ“ Installs all dependencies
- âœ“ Compiles the project
- âœ“ Builds the extension into .vsix
- âœ“ Installs the extension in CursorAI

ğŸ“– More details: [INSTALL.md](INSTALL.md)

### Method 3: Manual installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Zeed80/CursorAI_Ext_Rules.git
   cd CursorAI_Ext_Rules
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Build the extension:
   ```bash
   npm run package
   ```

4. Install the built .vsix file in CursorAI:
   ```bash
   code --install-extension cursor-ai-autonomous-extension-0.2.0.vsix
   ```

ğŸ“– More details: [BUILD.md](BUILD.md)

## âš¡ Quick Start

### 0. Prerequisites

**Option A: Local Models Only ($0 cost)**

1. Install [Ollama](https://ollama.ai/)
2. Download models:
   ```bash
   ollama pull codellama
   ollama pull mistral
   ollama pull llama2
   ```
3. Configure extension settings (see below)

**Option B: Hybrid Mode ($5-30/month)**

1. Install Ollama (optional)
2. Get API keys:
   - OpenAI: https://platform.openai.com/api-keys
   - Anthropic: https://console.anthropic.com/
   - Google: https://makersuite.google.com/app/apikey
3. Configure extension settings (see below)

**Option C: With CursorAI Integration (Optional)**

1. Have a CursorAI Pro plan
2. Complete Option A or B
3. Enable CursorAI integration in settings

### 1. Extension Activation

After installation, the extension activates automatically when opening a project.

### 2. Configure Settings

**Method 1: Through Settings Panel (Recommended)**

1. Press `Ctrl+Shift+A` (Quick Menu)
2. Select "âš™ Settings"
3. Configure:
   - **Agents tab** â€” select providers and models for each agent
   - **Autonomous Mode tab** (NEW!) â€” configure autonomous operation:
     - Enable autonomous mode
     - Set up hybrid mode (preferLocal, monthlyBudget)
     - Choose when to use CursorAI (useCursorAIFor)
     - Configure CursorAI integration (useChat, useComposer)

**Method 2: Through settings.json**

```json
{
  // Autonomous Mode Settings (NEW!)
  "cursor-autonomous.autonomousMode": true,
  
  // Hybrid Model Provider (NEW!)
  "cursor-autonomous.hybridMode": {
    "enabled": true,
    "preferLocal": true,
    "monthlyBudget": 20
  },
  
  // CursorAI Integration (NEW!)
  "cursor-autonomous.useCursorAIFor": ["consolidation", "file-editing"],
  "cursor-autonomous.cursorIntegration": {
    "useChat": true,
    "useComposer": true,
    "autoApplyComposer": false
  },
  
  // Agent Configuration
  "cursor-autonomous.agents": {
    "backend": {
      "enabled": true,
      "provider": "ollama",
      "model": "codellama",
      "temperature": 0.7
    },
    "frontend": {
      "enabled": true,
      "provider": "ollama",
      "model": "mistral",
      "temperature": 0.7
    }
    // ... other agents
  },
  
  // General Settings
  "cursor-autonomous.enableVirtualUser": false,
  "cursor-autonomous.autoImprove": true,
  "cursor-autonomous.enableOrchestrator": true
}
```

### 3. Enable Autonomous Mode

**Method 1: Through Quick Menu**
1. Press `Ctrl+Shift+A`
2. Select "ğŸ¤– Enable Autonomous Mode"

**Method 2: Through Command Palette**
- `Ctrl+Shift+P` â†’ "CursorAI Autonomous: Enable Autonomous Mode"

**Method 3: Through Status Bar**
- Click on `ğŸ¤– CursorAI` button in status bar

**What happens:**
- SwarmOrchestrator starts
- Agent workers initialize
- FileWatcher starts monitoring
- HealthMonitor starts tracking
- Status bar shows "Autonomous Mode Active" with green background

### 4. Create Tasks

**Method 1: Context Menu (NEW!)**
1. Right-click on file/folder in Explorer
2. Select "CursorAI Autonomous" submenu:
   - Create Task
   - Refactor (Extract Function/Class/Method/Component/Module)
   - Check Quality
   - Add Tests
   - Optimize Code

**Method 2: Quick Menu**
1. Press `Ctrl+Shift+A`
2. Select "â• Create Task" or "â• Create Prioritized Task" (NEW!)
3. Enter description
4. Select priority (immediate, high, medium, low)

**Method 3: Command**
- `Ctrl+Shift+P` â†’ "CursorAI Autonomous: Create Task"

### 5. Monitor System

**Status Bar:**
- `ğŸ¤– CursorAI âœ“` (green) â€” Autonomous mode active
- `ğŸ‘¤ Virtual User` â€” Toggle virtual user
- `ğŸ“Š Status` â€” Open status panel

**Dashboard Panel (NEW!):**
1. Press `Ctrl+Shift+A` â†’ "ğŸ“Š Autonomous Stats"
2. View:
   - Cost statistics per model/agent
   - Agent activity (tasks completed, time spent)
   - System health (worker status, queue size)
   - Budget usage (daily, monthly)

**Status Panel:**
1. Press `Ctrl+Shift+S`
2. View all agents and their tasks

## ğŸ“– Usage

### Working with Agents

#### Viewing Agent Status

**Sidebar (TreeView):**
1. Open CursorAI sidebar (ğŸ¤– icon)
2. Select "Agents"
3. Expand agent to view tasks

**Status Panel (WebView):**
1. Press `Ctrl+Shift+S`
2. View agent cards with details

#### Selecting Model for Agent

**Through Settings Panel:**
1. Press `Ctrl+Shift+A` â†’ "âš™ Settings"
2. Go to "Agents" tab
3. For each agent:
   - Select provider (Ollama, OpenAI, Anthropic, Google, LLM Studio, CursorAI)
   - Select model
   - Set temperature

**Available providers:**
- `ollama` â€” Ollama (local, free)
- `llmstudio` â€” LLM Studio (local, free)
- `openai` â€” OpenAI (GPT-3.5, GPT-4)
- `anthropic` â€” Anthropic (Claude)
- `google` â€” Google (Gemini)
- `cursorai` â€” CursorAI (requires Pro plan)

### Working with Tasks

#### Task Priorities (NEW!)

- **immediate** â€” Interrupts current work, executes immediately
- **high** â€” Executes as soon as possible
- **medium** â€” Normal queue
- **low** â€” Executes when agents are idle

#### Creating Prioritized Task

1. Press `Ctrl+Shift+A`
2. Select "â• Create Prioritized Task"
3. Enter description
4. Select priority
5. Task is added to queue with specified priority

#### Viewing Task Queue

**Dashboard Panel:**
- Shows tasks in queue grouped by priority
- Shows currently executing tasks
- Shows completed tasks

### Cost Management (NEW!)

#### Monitoring Costs

**Dashboard Panel:**
1. Press `Ctrl+Shift+A` â†’ "ğŸ“Š Autonomous Stats"
2. "Cost Statistics" section shows:
   - Total spent today/this month
   - Cost per model
   - Cost per agent
   - Budget usage percentage

#### Setting Budget

**Settings Panel:**
1. Go to "Autonomous Mode" tab
2. Set "Monthly Budget" (in USD)
3. System will:
   - Prefer free local models
   - Use cheap cloud APIs sparingly
   - Stop when budget is reached

#### Optimizing Costs

**Best practices:**
- âœ… Enable `preferLocal` in hybrid mode
- âœ… Set reasonable monthly budget ($10-30)
- âœ… Use CursorAI only for specific tasks
- âœ… Enable prompt caching (enabled by default)
- âœ… Monitor costs daily through dashboard

### Project Quality Check

**Launch check:**
- Command: `Cursor Autonomous: Run Quality Check`
- Context menu: Right-click on folder â†’ "Check Quality"

**Check areas:**
- `full` â€” Full quality check
- `code` â€” Code quality check
- `architecture` â€” Architecture check
- `performance` â€” Performance check
- `security` â€” Security check

## ğŸ—ï¸ Architecture

### Project Structure

```
CursorAI_Ext_Rules/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extension.ts                          # Entry point
â”‚   â”œâ”€â”€ orchestrator/                         # Orchestrator
â”‚   â”‚   â”œâ”€â”€ orchestrator.ts                  # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ self-learning-orchestrator.ts    # Self-learning
â”‚   â”‚   â”œâ”€â”€ swarm-orchestrator.ts           # Swarm coordination (NEW!)
â”‚   â”‚   â”œâ”€â”€ file-watcher.ts                  # Real-time monitoring (NEW!)
â”‚   â”‚   â”œâ”€â”€ autonomous-orchestrator-integration.ts  # Integration (NEW!)
â”‚   â”‚   â”œâ”€â”€ brainstorming-manager.ts         # Brainstorming
â”‚   â”‚   â”œâ”€â”€ solution-evaluator.ts            # Solution evaluation
â”‚   â”‚   â”œâ”€â”€ task-deviation-controller.ts     # Deviation control
â”‚   â”‚   â”œâ”€â”€ ensemble-refinement-manager.ts   # Ensemble refinement
â”‚   â”‚   â”œâ”€â”€ project-analyzer.ts              # Project analysis
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ agents/                               # Agents
â”‚   â”‚   â”œâ”€â”€ local-agent.ts                   # Base agent
â”‚   â”‚   â”œâ”€â”€ backend-agent.ts                 # Backend Developer
â”‚   â”‚   â”œâ”€â”€ frontend-agent.ts                # Frontend Developer
â”‚   â”‚   â”œâ”€â”€ architect-agent.ts               # Software Architect
â”‚   â”‚   â”œâ”€â”€ analyst-agent.ts                 # Data Analyst
â”‚   â”‚   â”œâ”€â”€ devops-agent.ts                  # DevOps Engineer
â”‚   â”‚   â”œâ”€â”€ qa-agent.ts                      # QA Engineer
â”‚   â”‚   â”œâ”€â”€ virtual-user.ts                  # Virtual user
â”‚   â”‚   â”œâ”€â”€ self-improver.ts                 # Self-improvement
â”‚   â”‚   â””â”€â”€ worker/                          # Autonomous workers (NEW!)
â”‚   â”‚       â”œâ”€â”€ agent-worker.ts              # Agent worker
â”‚   â”‚       â”œâ”€â”€ task-queue.ts                # Task queue
â”‚   â”‚       â”œâ”€â”€ message-bus.ts               # Message bus
â”‚   â”‚       â”œâ”€â”€ mcp-client.ts                # MCP client
â”‚   â”‚       â””â”€â”€ health-monitor.ts            # Health monitor
â”‚   â”œâ”€â”€ integration/                          # Integration
â”‚   â”‚   â”œâ”€â”€ cursor-api.ts                    # CursorAI API
â”‚   â”‚   â”œâ”€â”€ cursor-chat-integration.ts       # Chat integration (NEW!)
â”‚   â”‚   â”œâ”€â”€ cursor-composer-integration.ts   # Composer integration (NEW!)
â”‚   â”‚   â”œâ”€â”€ model-provider.ts                # Model provider
â”‚   â”‚   â”œâ”€â”€ model-providers/                 # Model providers (NEW!)
â”‚   â”‚   â”‚   â”œâ”€â”€ provider-manager.ts          # Provider manager
â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid-provider.ts           # Hybrid provider
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama-provider.ts           # Ollama
â”‚   â”‚   â”‚   â”œâ”€â”€ openai-provider.ts           # OpenAI
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic-provider.ts        # Anthropic
â”‚   â”‚   â”‚   â”œâ”€â”€ google-provider.ts           # Google
â”‚   â”‚   â”‚   â””â”€â”€ cursorai-provider.ts         # CursorAI
â”‚   â”‚   â”œâ”€â”€ settings-manager.ts              # Settings manager
â”‚   â”‚   â””â”€â”€ ui-integration.ts                # UI integration
â”‚   â”œâ”€â”€ optimization/                         # Optimization (NEW!)
â”‚   â”‚   â”œâ”€â”€ model-selector.ts                # Smart model selector
â”‚   â”‚   â”œâ”€â”€ prompt-cache.ts                  # Prompt caching
â”‚   â”‚   â”œâ”€â”€ request-batcher.ts               # Request batching
â”‚   â”‚   â””â”€â”€ cost-monitor.ts                  # Cost monitoring
â”‚   â”œâ”€â”€ self-improvement/                     # Self-improvement
â”‚   â”‚   â”œâ”€â”€ performance-monitor.ts
â”‚   â”‚   â”œâ”€â”€ knowledge-searcher.ts
â”‚   â”‚   â”œâ”€â”€ rule-updater.ts
â”‚   â”‚   â””â”€â”€ agent-optimizer.ts
â”‚   â”œâ”€â”€ storage/                              # Storage
â”‚   â”‚   â”œâ”€â”€ rules-integration.ts
â”‚   â”‚   â””â”€â”€ rules-versioning.ts
â”‚   â””â”€â”€ ui/                                   # UI
â”‚       â”œâ”€â”€ agents-status-tree.ts            # TreeView
â”‚       â”œâ”€â”€ status-panel.ts                  # Status panel
â”‚       â”œâ”€â”€ settings-panel.ts                # Settings panel (updated)
â”‚       â”œâ”€â”€ dashboard-panel.ts               # Dashboard (NEW!)
â”‚       â”œâ”€â”€ context-menu-provider.ts         # Context menu (NEW!)
â”‚       â”œâ”€â”€ analytics-panel.ts               # Analytics
â”‚       â””â”€â”€ quick-access-panel.ts            # Quick menu
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ README.md (English)
â””â”€â”€ README_RU.md (Russian)
```

### System Components

#### SwarmOrchestrator (NEW!)

Coordinates autonomous agent workers:
- Creates and manages AgentWorker instances
- Distributes tasks from TaskQueue
- Monitors worker health
- Handles real-time file changes

#### AgentWorker (NEW!)

Autonomous agent running in infinite loop:
- Pulls tasks from TaskQueue
- Communicates via MessageBus
- Uses MCPClient for operations
- Reports health status
- Auto-restarts on failures

#### TaskQueue (NEW!)

Prioritized task queue:
- 4 priority levels (immediate, high, medium, low)
- Swarm coordination (agents negotiate task assignment)
- Thread-safe operations
- Task persistence

#### MessageBus (NEW!)

Peer-to-peer communication:
- Topic-based pub/sub
- Direct agent-to-agent messaging
- Event broadcasting
- Message history

#### HybridModelProvider (NEW!)

Intelligent model selection:
- Assesses task complexity
- Chooses optimal model (local, cheap cloud, expensive cloud)
- Respects monthly budget
- Automatic fallback
- Cost tracking

#### FileWatcher (NEW!)

Real-time project monitoring:
- Watches file changes
- Triggers automatic tasks
- Debouncing for efficiency
- Pattern filtering

#### HealthMonitor (NEW!)

Agent health tracking:
- Checks worker heartbeats
- Detects stuck agents
- Auto-restarts failed workers
- Reports system health

#### MCPClient (NEW!)

Multi-Agent Communication Protocol:
- File operations (CRUD, search)
- Git operations (status, commit, branch, merge, stash, rebase)
- Code search (semantic, grep, references)
- Test runner integration
- Linter integration

## ğŸ› ï¸ Development

### Requirements

- **Node.js** version 18 or higher
- **TypeScript** 5.0 or higher
- **VS Code** 1.80 or higher
- **CursorAI** (for testing)

### Installing Dependencies

```bash
npm install
```

### Compilation

```bash
npm run compile
```

Or for automatic recompilation:

```bash
npm run watch
```

### Build

```bash
npm run package
```

### Testing

```bash
npm test
```

### Running in Development Mode

1. Open the project in VS Code
2. Press `F5`
3. Extension Development Host window opens
4. Extension runs in debug mode

## ğŸ“š Documentation

- [README.md](README.md) â€” Main documentation (English)
- [README_RU.md](README_RU.md) â€” ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ (Russian)
- [BUILD.md](BUILD.md) â€” Build instructions
- [INSTALL.md](INSTALL.md) â€” Installation instructions
- [QUICK_INSTALL.md](QUICK_INSTALL.md) â€” Quick installation
- [QUICK_ACCESS.md](QUICK_ACCESS.md) â€” Quick access guide
- [UI_FEATURES.md](UI_FEATURES.md) â€” UI features
- [IMPROVEMENTS.md](IMPROVEMENTS.md) â€” Integration improvements
- [CHANGELOG.md](CHANGELOG.md) â€” Change history

## ğŸ’° Cost Comparison

### Scenario 1: Free ($0/month)
```json
{
  "hybridMode": {
    "enabled": true,
    "preferLocal": true,
    "monthlyBudget": 0
  },
  "useCursorAIFor": ["never"],
  "agents": {
    "backend": { "provider": "ollama", "model": "codellama" },
    "frontend": { "provider": "ollama", "model": "mistral" }
  }
}
```
**Result:** Fully functional with local models only

### Scenario 2: Budget ($5-10/month)
```json
{
  "hybridMode": {
    "enabled": true,
    "preferLocal": true,
    "monthlyBudget": 10
  },
  "useCursorAIFor": ["never"],
  "agents": {
    "backend": { "provider": "openai", "model": "gpt-3.5-turbo" },
    "frontend": { "provider": "ollama", "model": "mistral" }
  }
}
```
**Result:** Hybrid mode with cheap cloud APIs for complex tasks

### Scenario 3: Premium ($20-50/month)
```json
{
  "hybridMode": {
    "enabled": true,
    "preferLocal": false,
    "monthlyBudget": 50
  },
  "useCursorAIFor": ["consolidation", "file-editing"],
  "agents": {
    "backend": { "provider": "openai", "model": "gpt-4" },
    "frontend": { "provider": "anthropic", "model": "claude-3-opus" }
  }
}
```
**Result:** Best quality with top models + CursorAI integration

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. **Fork** the repository
2. Create a **feature branch** (`git checkout -b feature/AmazingFeature`)
3. **Commit** changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to branch (`git push origin feature/AmazingFeature`)
5. Open a **Pull Request**

### Development Rules

- Follow TypeScript/ESLint code style
- Add tests for new functionality
- Update documentation when changing API
- Write clear commit messages

## ğŸ“ License

This project is distributed under the **MIT License**.

Full license text: [LICENSE](LICENSE)

## ğŸ†˜ Support

### Report an Issue

1. Check existing [Issues](https://github.com/Zeed80/CursorAI_Ext_Rules/issues)
2. Create a new Issue with detailed description

### Ask a Question

- Create a [Discussion](https://github.com/Zeed80/CursorAI_Ext_Rules/discussions)
- Or contact through Issues

### Troubleshooting

#### Extension Not Activating

1. Check logs: View â†’ Output â†’ "Log (Extension Host)"
2. Ensure dependencies are installed: `npm install`
3. Check compiled files in `out/` directory
4. Reload window: `Ctrl+Shift+P` â†’ "Developer: Reload Window"

#### Autonomous Mode Not Starting

1. Check settings: `cursor-autonomous.autonomousMode` should be `true`
2. Check if agents are configured in settings
3. For local models: ensure Ollama is running
4. Check logs for errors

#### "Local agent X not found"

1. Open Settings Panel: `Ctrl+Shift+A` â†’ "âš™ Settings"
2. Go to "Agents" tab
3. Enable and configure all required agents
4. Ensure providers are installed (Ollama, API keys)

#### Ollama Connection Failed

1. Check Ollama is running: `ollama list`
2. Check Ollama server: `curl http://localhost:11434/api/tags`
3. Install models: `ollama pull codellama`
4. Restart extension: `Ctrl+Shift+P` â†’ "Developer: Reload Window"

#### High API Costs

1. Enable `preferLocal` in hybrid mode
2. Lower `monthlyBudget`
3. Use cheaper models (gpt-3.5-turbo instead of gpt-4)
4. Disable CursorAI integration: `useCursorAIFor: ["never"]`
5. Monitor costs in Dashboard Panel

## ğŸ¯ Roadmap

### Planned Features

- [ ] More LLM providers (Cohere, Mistral AI, Llama API)
- [ ] Enhanced swarm intelligence (voting, consensus)
- [ ] Cloud synchronization for rules and settings
- [ ] Team collaboration features
- [ ] Advanced cost analytics and predictions
- [ ] Automatic model fine-tuning on project data

### Known Limitations

- Some features may use fallback methods
- Internet connection required for cloud APIs and web search
- Local models may be slower than cloud APIs
- Autonomous mode consumes system resources

## ğŸ™ Acknowledgments

- [CursorAI](https://cursor.sh/) â€” excellent IDE
- [Ollama](https://ollama.ai/) â€” local LLM runner
- [VS Code Extension API](https://code.visualstudio.com/api) â€” powerful API
- All project contributors

## ğŸ“ Contacts

- **GitHub**: [@Zeed80](https://github.com/Zeed80)
- **Issues**: [GitHub Issues](https://github.com/Zeed80/CursorAI_Ext_Rules/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Zeed80/CursorAI_Ext_Rules/discussions)

---

<div align="center">

[English](#-cursorai-autonomous-extension-english) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README_RU.md)

**Made with â¤ï¸ by the power of AI**

</div>
